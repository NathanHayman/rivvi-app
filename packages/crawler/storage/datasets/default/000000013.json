{
	"title": "How Assistants work - OpenAI API",
	"url": "https://platform.openai.com/docs/assistants/how-it-works",
	"html": "Overview\nDocumentation\nAPI reference\nExamples\nLog in\nSign up‍\nSearch\n⌘\nK\nGET STARTED\nIntroduction\nQuickstart\nModels\nTutorials\nChangelog\nCAPABILITIES\nText generation\nFunction calling\nEmbeddings\nFine-tuning\nImage generation\nVision\nText-to-speech\nSpeech-to-text\nModeration\nASSISTANTS\nOverview\nHow Assistants work\nObjects\nCreating assistants\nManaging Threads and Messages\nRuns and Run Steps\nLimitations\nTools\nGUIDES\nPrompt engineering\nProduction best practices\nSafety best practices\nRate limits\nError codes\nLibraries\nDeprecations\nPolicies\nCHATGPT\nActions\nPlugins\nHow Assistants work Beta\n\nThe Assistants API is designed to help developers build powerful AI assistants capable of performing a variety of tasks.\n\nThe Assistants API is in beta and we are actively working on adding more functionality. Share your feedback in our Developer Forum!\nAssistants can call OpenAI’s models with specific instructions to tune their personality and capabilities.\nAssistants can access multiple tools in parallel. These can be both OpenAI-hosted tools — like Code interpreter and Knowledge retrieval — or tools you build / host (via Function calling).\nAssistants can access persistent Threads. Threads simplify AI application development by storing message history and truncating it when the conversation gets too long for the model’s context length. You create a Thread once, and simply append Messages to it as your users reply.\nAssistants can access Files in several formats — either as part of their creation or as part of Threads between Assistants and users. When using tools, Assistants can also create files (e.g., images, spreadsheets, etc) and cite files they reference in the Messages they create.\nObjects\n\nOBJECT\tWHAT IT REPRESENTS\nAssistant\tPurpose-built AI that uses OpenAI’s models and calls tools\nThread\tA conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context.\nMessage\tA message created by an Assistant or a user. Messages can include text, images, and other files. Messages stored as a list on the Thread.\nRun\tAn invocation of an Assistant on a Thread. The Assistant uses it’s configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.\nRun Step\tA detailed list of steps the Assistant took as part of a Run. An Assistant can call tools or create Messages during it’s run. Examining Run Steps allows you to introspect how the Assistant is getting to it’s final results.\nCreating Assistants\nWe recommend using OpenAI’s latest models with the Assistants API for best results and maximum compatibility with tools.\n\nTo get started, creating an Assistant only requires specifying the model to use. But you can further customize the behavior of the Assistant:\n\nUse the instructions parameter to guide the personality of the Assistant and define it’s goals. Instructions are similar to system messages in the Chat Completions API.\nUse the tools parameter to give the Assistant access to up to 128 tools. You can give it access to OpenAI-hosted tools like code_interpreter and retrieval, or call a third-party tools via a function calling.\nUse the file_ids parameter to give the tools like code_interpreter and retrieval access to files. Files are uploaded using the File upload endpoint and must have the purpose set to assistants to be used with this API.\n\nFor example, to create an Assistant that can create data visualization based on a .csv file, first upload a file.\n\npython\nSelect library\npython\nnode.js\ncurl\nCopy‍\n1\n2\n3\n4\n\nfile = client.files.create(\n  file=open(\"speech.py\", \"rb\"),\n  purpose='assistants'\n)\n\nAnd then create the Assistant with the uploaded file.\n\npython\nSelect library\npython\nnode.js\ncurl\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\nassistant = client.beta.assistants.create(\n  name=\"Data visualizer\",\n  description=\"You are great at creating beautiful data visualizations. You analyze data present in .csv files, understand trends, and come up with data visualizations relevant to those trends. You also share a brief text summary of the trends observed.\",\n  model=\"gpt-4-1106-preview\",\n  tools=[{\"type\": \"code_interpreter\"}],\n  file_ids=[file.id]\n)\n\nYou can attach a maximum of 20 files per Assistant, and they can be at most 512 MB each. The size of all the files uploaded by your organization should not exceed 100 GB. You can request an increase in this storage limit using our help center. In addition to the 512 MB file size limit, each file can only contain 2,000,000 tokens. Assistant or Message creation will fail if any attached files exceed the token limit.\n\nYou can also use the AssistantFile object to create, delete, or view associations between Assistant and File objects. Note that deleting an AssistantFile doesn’t delete the original File object, it simply deletes the association between that File and the Assistant. To delete a File, use the File delete endpoint instead.\n\nManaging Threads and Messages\n\nThreads and Messages represent a conversation session between an Assistant and a user. There is no limit to the number of Messages you can store in a Thread. Once the size of the Messages exceeds the context window of the model, the Thread will attempt to include as many messages as possible that fit in the context window and drop the oldest messages.\n\nYou can create a Thread with an initial list of Messages like this:\n\npython\nSelect library\npython\nnode.js\ncurl\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nthread = client.beta.threads.create(\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": \"Create 3 data visualizations based on the trends in this file.\",\n      \"file_ids\": [file.id]\n    }\n  ]\n)\n\nMessages can contain text, images, or files. At the moment, user-created Messages cannot contain image files but we plan to add support for this in the future. Messages also have the same file size and token limits as Assistants (512 MB file size limit and 2,000,000 token limit).\n\nContext window management\n\nThe Assistants API automatically manages the context window such that you never exceed the model's context length. Once the size of the Messages in a Thread exceeds the context window of the model, the Thread will attempt to include as many messages as possible that fit in the context window and drop the oldest messages. Note that this truncation strategy will evolve over time to become more sophisticated.\n\nCurrently, the Assistant will include the maximum number of messages that fit in the context length. We plan to explore the ability for you to control the input / output token count beyond the model you select, as well as the ability to automatically generate summaries of the previous messages and pass that as context. If your use case requires a more advanced level of control, you can manually generate summaries and control context with the Chat Completion API.\n\nMessage annotations\n\nMessages created by Assistants may contain annotations within the content array of the object. Annotations provide information around how you should annotate the text in the Message.\n\nThere are two types of Annotations:\n\nfile_citation: File citations are created by the retrieval tool and define references to a specific quote in a specific file that was uploaded and used by the Assistant to generate the response.\nfile_path: File path annotations are created by the code_interpreter tool and contain references to the files generated by the tool.\n\nWhen annotations are present in the Message object, you'll see illegible model-generated substrings in the text that you should replace with the annotations. These strings may look something like 【13†source】 or sandbox:/mnt/data/file.csv. Here’s an example python code snippet that replaces these strings with information present in the annotations.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n# Retrieve the message object\nmessage = client.beta.threads.messages.retrieve(\n  thread_id=\"...\",\n  message_id=\"...\"\n)\n\n# Extract the message content\nmessage_content = message.content[0].text\nannotations = message_content.annotations\ncitations = []\n\n# Iterate over the annotations and add footnotes\nfor index, annotation in enumerate(annotations):\n    # Replace the text with a footnote\n    message_content.value = message_content.value.replace(annotation.text, f' [{index}]')\n\n    # Gather citations based on annotation attributes\n    if (file_citation := getattr(annotation, 'file_citation', None)):\n        cited_file = client.files.retrieve(file_citation.file_id)\n        citations.append(f'[{index}] {file_citation.quote} from {cited_file.filename}')\n    elif (file_path := getattr(annotation, 'file_path', None)):\n        cited_file = client.files.retrieve(file_path.file_id)\n        citations.append(f'[{index}] Click <here> to download {cited_file.filename}')\n        # Note: File download functionality not implemented above for brevity\n\n# Add footnotes to the end of the message before displaying to user\nmessage_content.value += '\\n' + '\\n'.join(citations)\nRuns and Run Steps\n\nWhen you have all the context you need from your user in the Thread, you can run the Thread with an Assistant of your choice.\n\npython\nSelect library\npython\nnode.js\ncurl\nCopy‍\n1\n2\n3\n4\n\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id\n)\n\nBy default, a Run will use the model and tools configuration specified in Assistant object, but you can override most of these when creating the Run for added flexibility:\n\npython\nSelect library\npython\nnode.js\ncurl\nCopy‍\n1\n2\n3\n4\n5\n6\n7\n\nrun = client.beta.threads.runs.create(\n  thread_id=thread.id,\n  assistant_id=assistant.id,\n  model=\"gpt-4-1106-preview\",\n  instructions=\"additional instructions\",\n  tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}]\n)\n\nNote: file_ids associated with the Assistant cannot be overridden during Run creation. You must use the modify Assistant endpoint to do this.\n\nRun lifecycle\n\nRun objects can have multiple statuses.\n\nSTATUS\tDEFINITION\nqueued\tWhen Runs are first created or when you complete the required_action, they are moved to a queued status. They should almost immediately move to in_progress.\nin_progress\tWhile in_progress, the Assistant uses the model and tools to perform steps. You can view progress being made by the Run by examining the Run Steps.\ncompleted\tThe Run successfully completed! You can now view all Messages the Assistant added to the Thread, and all the steps the Run took. You can also continue the conversation by adding more user Messages to the Thread and creating another Run.\nrequires_action\tWhen using the Function calling tool, the Run will move to a required_action state once the model determines the names and arguments of the functions to be called. You must then run those functions and submit the outputs before the run proceeds. If the outputs are not provided before the expires_at timestamp passes (roughly 10 mins past creation), the run will move to an expired status.\nexpired\tThis happens when the function calling outputs were not submitted before expires_at and the run expires. Additionally, if the runs take too long to execute and go beyond the time stated in expires_at, our systems will expire the run.\ncancelling\tYou can attempt to cancel an in_progress run using the Cancel Run endpoint. Once the attempt to cancel succeeds, status of the Run moves to cancelled. Cancellation is attempted but not guaranteed.\ncancelled\tRun was successfully cancelled.\nfailed\tYou can view the reason for the failure by looking at the last_error object in the Run. The timestamp for the failure will be recorded under failed_at.\nPolling for updates\n\nIn order to keep the status of your run up to date, you will have to periodically retrieve the Run object. You can check the status of the run each time you retrieve the object to determine what your application should do next. We plan to add support for streaming to make this simpler in the near future.\n\nThread locks\n\nWhen a Run is in_progress and not in a terminal state, the Thread is locked. This means that:\n\nNew Messages cannot be added to the Thread.\nNew Runs cannot be created on the Thread.\nRun steps\n\nRun step statuses have the same meaning as Run statuses.\n\nMost of the interesting detail in the Run Step object lives in the step_details field. There can be two types of step details:\n\nmessage_creation: This Run Step is created when the Assistant creates a Message on the Thread.\ntool_calls: This Run Step is created when the Assistant calls a tool. Details around this are covered in the relevant sections of the Tools guide.\nData access guidance\n\nCurrently, assistants, threads, messages, and files created via the API are scoped to the entire organization. As such, any person with API key access to the organization is able to read or write assistants, threads, messages, and files in the organization.\n\nWe strongly recommend the following data access controls:\n\nImplement authorization. Before performing reads or writes on assistants, threads, messages, and files, ensure that the end-user is authorized to do so. For example, store in your database the object IDs that the end-user has access to, and check it before fetching the object ID with the API.\nRestrict API key access. Carefully consider who in your organization should have API keys and periodically audit this list. API keys enable a wide range of operations including reading and modifying sensitive information, such as messages and files.\nCreate separate accounts. Consider creating separate accounts / organizations for different applications in order to isolate data across multiple applications.\nLimitations\n\nDuring this beta, there are several known limitations we are looking to address in the coming weeks and months. We will publish a changelog on this page when we add support for additional functionality.\n\nSupport for streaming output (including Messages and Run Steps).\nSupport for notifications to share object status updates without the need for polling.\nSupport for DALL·E or Browsing as a tool.\nSupport for user message creation with images.\n\nWe are actively working to add these features and welcome feedback on our Developer Forum as to what else would make building an Assistant more powerful.\n\nNext\nLearn more about Tools"
}