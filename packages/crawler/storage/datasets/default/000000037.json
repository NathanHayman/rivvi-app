{
	"title": "Models - OpenAI API",
	"url": "https://platform.openai.com/docs/models/gpt-3",
	"html": "Overview\nDocumentation\nAPI reference\nExamples\nLog in\nSign up‍\nSearch\n⌘\nK\nGET STARTED\nIntroduction\nQuickstart\nModels\nOverview\nModel updates\nGPT-4\nGPT-3.5\nDALL·E\nTTS\nWhisper\nEmbeddings\nModeration\nGPT-3\nHow we use your data\nEndpoint compatibility\nTutorials\nChangelog\nCAPABILITIES\nText generation\nFunction calling\nEmbeddings\nFine-tuning\nImage generation\nVision\nText-to-speech\nSpeech-to-text\nModeration\nASSISTANTS\nOverview\nHow Assistants work\nTools\nGUIDES\nPrompt engineering\nProduction best practices\nSafety best practices\nRate limits\nError codes\nLibraries\nDeprecations\nPolicies\nCHATGPT\nActions\nPlugins\nModels\n\nNew models launched at DevDay\n\nWe are excited to announce the preview release of GPT-4 Turbo (128k context window) and an updated GPT-3.5 Turbo (16k context window). Among other things, both models come with improved instruction following, JSON mode, more reproducible outputs, and parallel function calling.\nLearn more.\nOverview\n\nThe OpenAI API is powered by a diverse set of models with different capabilities and price points. You can also make customizations to our models for your specific use case with fine-tuning.\n\nMODEL\tDESCRIPTION\nGPT-4 and GPT-4 Turbo\tA set of models that improve on GPT-3.5 and can understand as well as generate natural language or code\nGPT-3.5\tA set of models that improve on GPT-3 and can understand as well as generate natural language or code\nDALL·E\tA model that can generate and edit images given a natural language prompt\nTTS\tA set of models that can convert text into natural sounding spoken audio\nWhisper\tA model that can convert audio into text\nEmbeddings\tA set of models that can convert text into a numerical form\nModeration\tA fine-tuned model that can detect whether text may be sensitive or unsafe\nGPT base\tA set of models without instruction following that can understand as well as generate natural language or code\nGPT-3Legacy\tA set of models that can understand and generate natural language\nDeprecated\tA full list of models that have been deprecated along with the suggested replacement\n\nWe have also published open source models including Point-E, Whisper, Jukebox, and CLIP.\n\nVisit our model index for researchers to learn more about which models have been featured in our research papers and the differences between model series like InstructGPT and GPT-3.5.\n\nContinuous model upgrades\n\ngpt-3.5-turbo, gpt-4, and gpt-4-32k point to the latest model version. You can verify this by looking at the response object after sending a request. The response will include the specific model version used (e.g. gpt-3.5-turbo-0613).\n\nWe also offer static model versions that developers can continue using for at least three months after an updated model has been introduced. With the new cadence of model updates, we are also giving people the ability to contribute evals to help us improve the model for different use cases. If you are interested, check out the OpenAI Evals repository.\n\nThe following models are the temporary snapshots, which we have already announced the deprecation dates of along with their replacement. If you want to use the latest model version, use the standard model names like gpt-4 or gpt-3.5-turbo.\n\nMODEL NAME\tDISCONTINUATION DATE\tREPLACEMENT MODEL\ngpt-3.5-turbo-0613\tJun 13, 2024\tgpt-3.5-turbo-1106\ngpt-3.5-turbo-0301\tJun 13, 2024\tgpt-3.5-turbo-1106\ngpt-4-0314\tJun 13, 2024\tgpt-4-0613\ngpt-4-32k-0314\tJun 13, 2024\tgpt-4-32k-0613\n\nLearn more about model deprecation on our deprecation page.\n\nGPT-4 and GPT-4 Turbo\n\nGPT-4 is a large multimodal model (accepting text or image inputs and outputting text) that can solve difficult problems with greater accuracy than any of our previous models, thanks to its broader general knowledge and advanced reasoning capabilities. GPT-4 is available in the OpenAI API to paying customers. Like gpt-3.5-turbo, GPT-4 is optimized for chat but works well for traditional completions tasks using the Chat Completions API. Learn how to use GPT-4 in our GPT guide.\n\nMODEL\tDESCRIPTION\tCONTEXT WINDOW\tTRAINING DATA\ngpt-4-1106-preview\tGPT-4 TurboNew\nThe latest GPT-4 model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Learn more.\t128,000 tokens\tUp to Apr 2023\ngpt-4-vision-preview\tGPT-4 Turbo with visionNew\nAbility to understand images, in addition to all other GPT-4 Turbo capabilties. Returns a maximum of 4,096 output tokens. This is a preview model version and not suited yet for production traffic. Learn more.\t128,000 tokens\tUp to Apr 2023\ngpt-4\tCurrently points to gpt-4-0613. See continuous model upgrades.\t8,192 tokens\tUp to Sep 2021\ngpt-4-32k\tCurrently points to gpt-4-32k-0613. See continuous model upgrades.\t32,768 tokens\tUp to Sep 2021\ngpt-4-0613\tSnapshot of gpt-4 from June 13th 2023 with improved function calling support.\t8,192 tokens\tUp to Sep 2021\ngpt-4-32k-0613\tSnapshot of gpt-4-32k from June 13th 2023 with improved function calling support.\t32,768 tokens\tUp to Sep 2021\ngpt-4-0314\nLegacy\tSnapshot of gpt-4 from March 14th 2023 with function calling support. This model version will be deprecated on June 13th 2024.\t8,192 tokens\tUp to Sep 2021\ngpt-4-32k-0314\nLegacy\tSnapshot of gpt-4-32k from March 14th 2023 with function calling support. This model version will be deprecated on June 13th 2024.\t32,768 tokens\tUp to Sep 2021\n\nFor many basic tasks, the difference between GPT-4 and GPT-3.5 models is not significant. However, in more complex reasoning situations, GPT-4 is much more capable than any of our previous models.\n\nMultilingual capabilities\n\nGPT-4 outperforms both previous large language models and as of 2023, most state-of-the-art systems (which often have benchmark-specific training or hand-engineering). On the MMLU benchmark, an English-language suite of multiple-choice questions covering 57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but also demonstrates strong performance in other languages.\n\nGPT-3.5\n\nGPT-3.5 models can understand and generate natural language or code. Our most capable and cost effective model in the GPT-3.5 family is gpt-3.5-turbo which has been optimized for chat using the Chat Completions API but works well for traditional completions tasks as well.\n\nMODEL\tDESCRIPTION\tCONTEXT WINDOW\tTRAINING DATA\ngpt-3.5-turbo-1106\tUpdated GPT 3.5 TurboNew\nThe latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. Returns a maximum of 4,096 output tokens. Learn more.\t16,385 tokens\tUp to Sep 2021\ngpt-3.5-turbo\tCurrently points to gpt-3.5-turbo-0613. Will point to gpt-3.5-turbo-1106 starting Dec 11, 2023. See continuous model upgrades.\t4,096 tokens\tUp to Sep 2021\ngpt-3.5-turbo-16k\tCurrently points to gpt-3.5-turbo-0613. Will point to gpt-3.5-turbo-1106 starting Dec 11, 2023. See continuous model upgrades.\t16,385 tokens\tUp to Sep 2021\ngpt-3.5-turbo-instruct\tSimilar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions.\t4,096 tokens\tUp to Sep 2021\ngpt-3.5-turbo-0613\nLegacy\tSnapshot of gpt-3.5-turbo from June 13th 2023. Will be deprecated on June 13, 2024.\t4,096 tokens\tUp to Sep 2021\ngpt-3.5-turbo-16k-0613\nLegacy\tSnapshot of gpt-3.5-16k-turbo from June 13th 2023. Will be deprecated on June 13, 2024.\t16,385 tokens\tUp to Sep 2021\ngpt-3.5-turbo-0301\nLegacy\tSnapshot of gpt-3.5-turbo from March 1st 2023. Will be deprecated on June 13th 2024.\t4,096 tokens\tUp to Sep 2021\ntext-davinci-003\nLegacy\tCan do language tasks with better quality and consistency than the curie, babbage, or ada models. Will be deprecated on Jan 4th 2024.\t4,096 tokens\tUp to Jun 2021\ntext-davinci-002\nLegacy\tSimilar capabilities to text-davinci-003 but trained with supervised fine-tuning instead of reinforcement learning. Will be deprecated on Jan 4th 2024.\t4,096 tokens\tUp to Jun 2021\ncode-davinci-002\nLegacy\tOptimized for code-completion tasks. Will be deprecated on Jan 4th 2024.\t8,001 tokens\tUp to Jun 2021\n\nWe recommend using gpt-3.5-turbo over the other GPT-3.5 models because of its lower cost and improved performance.\n\nDALL·E\n\nDALL·E is a AI system that can create realistic images and art from a description in natural language. DALL·E 3 currently supports the ability, given a prompt, to create a new image with a specific size. DALL·E 2 also support the ability to edit an existing image, or create variations of a user provided image.\n\nDALL·E 3 is available through our Images API along with DALL·E 2. You can try DALL·E 3 through ChatGPT Plus.\n\nMODEL\tDESCRIPTION\ndall-e-3\tDALL·E 3New\nThe latest DALL·E model released in Nov 2023. Learn more.\ndall-e-2\tThe previous DALL·E model released in Nov 2022. The 2nd iteration of DALL·E with more realistic, accurate, and 4x greater resolution images than the original model.\nTTS\n\nTTS is an AI model that converts text to natural sounding spoken text. We offer two different model variates, tts-1 is optimized for real time text to speech use cases and tts-1-hd is optimized for quality. These models can be used with the Speech endpoint in the Audio API.\n\nMODEL\tDESCRIPTION\ntts-1\tText-to-speech 1New\nThe latest text to speech model, optimized for speed.\ntts-1-hd\tText-to-speech 1 HDNew\nThe latest text to speech model, optimized for quality.\nWhisper\n\nWhisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. The Whisper v2-large model is currently available through our API with the whisper-1 model name.\n\nCurrently, there is no difference between the open source version of Whisper and the version available through our API. However, through our API, we offer an optimized inference process which makes running Whisper through our API much faster than doing it through other means. For more technical details on Whisper, you can read the paper.\n\nEmbeddings\n\nEmbeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text. Our second generation embedding model, text-embedding-ada-002 is a designed to replace the previous 16 first-generation embedding models at a fraction of the cost. Embeddings are useful for search, clustering, recommendations, anomaly detection, and classification tasks. You can read more about our latest embedding model in the announcement blog post.\n\nModeration\n\nThe Moderation models are designed to check whether content complies with OpenAI's usage policies. The models provide classification capabilities that look for content in the following categories: hate, hate/threatening, self-harm, sexual, sexual/minors, violence, and violence/graphic. You can find out more in our moderation guide.\n\nModeration models take in an arbitrary sized input that is automatically broken up into chunks of 4,096 tokens. In cases where the input is more than 32,768 tokens, truncation is used which in a rare condition may omit a small number of tokens from the moderation check.\n\nThe final results from each request to the moderation endpoint shows the maximum value on a per category basis. For example, if one chunk of 4K tokens had a category score of 0.9901 and the other had a score of 0.1901, the results would show 0.9901 in the API response since it is higher.\n\nMODEL\tDESCRIPTION\tMAX TOKENS\ntext-moderation-latest\tMost capable moderation model. Accuracy will be slightly higher than the stable model.\t32,768\ntext-moderation-stable\tAlmost as capable as the latest model, but slightly older.\t32,768\nGPT base\n\nGPT base models can understand and generate natural language or code but are not trained with instruction following. These models are made to be replacements for our original GPT-3 base models and use the legacy Completions API. Most customers should use GPT-3.5 or GPT-4.\n\nMODEL\tDESCRIPTION\tMAX TOKENS\tTRAINING DATA\nbabbage-002\tReplacement for the GPT-3 ada and babbage base models.\t16,384 tokens\tUp to Sep 2021\ndavinci-002\tReplacement for the GPT-3 curie and davinci base models.\t16,384 tokens\tUp to Sep 2021\nGPT-3 Legacy\n\nGPT-3 models can understand and generate natural language. These models were superseded by the more powerful GPT-3.5 generation models. However, the original GPT-3 base models (davinci, curie, ada, and babbage) are current the only models that are available to fine-tune.\n\nMODEL\tDESCRIPTION\tMAX TOKENS\tTRAINING DATA\ntext-curie-001\tVery capable, faster and lower cost than Davinci.\t2,049 tokens\tUp to Oct 2019\ntext-babbage-001\tCapable of straightforward tasks, very fast, and lower cost.\t2,049 tokens\tUp to Oct 2019\ntext-ada-001\tCapable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\t2,049 tokens\tUp to Oct 2019\ndavinci\tMost capable GPT-3 model. Can do any task the other models can do, often with higher quality.\t2,049 tokens\tUp to Oct 2019\ncurie\tVery capable, but faster and lower cost than Davinci.\t2,049 tokens\tUp to Oct 2019\nbabbage\tCapable of straightforward tasks, very fast, and lower cost.\t2,049 tokens\tUp to Oct 2019\nada\tCapable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\t2,049 tokens\tUp to Oct 2019\nHow we use your data\n\nYour data is your data.\n\nAs of March 1, 2023, data sent to the OpenAI API will not be used to train or improve OpenAI models (unless you explicitly opt in). One advantage to opting in is that the models may get better at your use case over time.\n\nTo help identify abuse, API data may be retained for up to 30 days, after which it will be deleted (unless otherwise required by law). For trusted customers with sensitive applications, zero data retention may be available. With zero data retention, request and response bodies are not persisted to any logging mechanism and exist only in memory in order to serve the request.\n\nNote that this data policy does not apply to OpenAI's non-API consumer services like ChatGPT or DALL·E Labs.\n\nDefault usage policies by endpoint\nENDPOINT\tDATA USED FOR TRAINING\tDEFAULT RETENTION\tELIGIBLE FOR ZERO RETENTION\n/v1/chat/completions*\tNo\t30 days\tYes, except image inputs*\n/v1/files\tNo\tUntil deleted by customer\tNo\n/v1/assistants\tNo\tUntil deleted by customer\tNo\n/v1/threads\tNo\t30 days\tNo\n/v1/threads/messages\tNo\t30 days\tNo\n/v1/threads/runs\tNo\t30 days\tNo\n/v1/threads/runs/steps\tNo\t30 days\tNo\n/v1/images/generations\tNo\t30 days\tNo\n/v1/images/edits\tNo\t30 days\tNo\n/v1/images/variations\tNo\t30 days\tNo\n/v1/embeddings\tNo\t30 days\tYes\n/v1/audio/transcriptions\tNo\tZero data retention\t-\n/v1/audio/translations\tNo\tZero data retention\t-\n/v1/audio/speech\tNo\t30 days\tNo\n/v1/fine_tuning/jobs\tNo\tUntil deleted by customer\tNo\n/v1/fine-tunes\tNo\tUntil deleted by customer\tNo\n/v1/moderations\tNo\tZero data retention\t-\n/v1/completions\tNo\t30 days\tYes\n/v1/edits\tNo\t30 days\tYes\n\n* Image inputs via the gpt-4-vision-preview model are not eligible for zero retention.\n\nFor details, see our API data usage policies. To learn more about zero retention, get in touch with our sales team.\n\nModel endpoint compatibility\nENDPOINT\tLATEST MODELS\n/v1/assistants\tAll models except gpt-3.5-turbo-0301 supported. retrieval tool requires gpt-4-1106-preview or gpt-3.5-turbo-1106.\n/v1/audio/transcriptions\twhisper-1\n/v1/audio/translations\twhisper-1\n/v1/audio/speech\ttts-1, tts-1-hd\n/v1/chat/completions\tgpt-4 and dated model releases, gpt-4-1106-preview, gpt-4-vision-preview, gpt-4-32k and dated model releases, gpt-3.5-turbo and dated model releases, gpt-3.5-turbo-16k and dated model releases, fine-tuned versions of gpt-3.5-turbo\n/v1/completions (Legacy)\tgpt-3.5-turbo-instruct, babbage-002, davinci-002\n/v1/embeddings\ttext-embedding-ada-002\n/v1/fine_tuning/jobs\tgpt-3.5-turbo, babbage-002, davinci-002\n/v1/moderations\ttext-moderation-stable, text-moderation-latest\n/v1/images/generations\tdall-e-2, dall-e-3\n\nThis list excludes all of our deprecated models."
}